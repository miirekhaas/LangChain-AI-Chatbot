import os
import streamlit as st
from utils.helpers import (
    load_pdf_from_upload,
    create_vector_store,
    get_conversational_chain
)

# App config
st.set_page_config(page_title="ğŸ“„ OpenRouter PDF Chatbot", layout="wide")
st.title("ğŸ“„ OpenRouter Chatbot with PDF")

# Set OpenRouter API Key
openrouter_key = st.secrets.get("OPENROUTER_API_KEY") or os.getenv("OPENROUTER_API_KEY")
if not openrouter_key:
    st.error("âŒ OPENROUTER_API_KEY not found. Please set it in Streamlit secrets or as an environment variable.")
    st.stop()
else:
    os.environ["OPENAI_API_KEY"] = openrouter_key
    os.environ["OPENAI_API_BASE"] = "https://openrouter.ai/api/v1"

# Upload PDF
uploaded_file = st.file_uploader("Upload a PDF", type="pdf", key="pdf_upload")

if uploaded_file:
    st.success(f"âœ… PDF uploaded: {uploaded_file.name}")

    with st.spinner("ğŸ” Processing your PDF..."):
        try:
            pages = load_pdf_from_upload(uploaded_file)
        except Exception as e:
            st.error(f"âŒ Error loading PDF: {e}")
            st.stop()

    if not pages:
        st.error("âŒ No text extracted from PDF.")
        st.stop()

    st.info(f"ğŸ“„ Loaded {len(pages)} page(s).")

    with st.spinner("ğŸ” Creating vector store..."):
        try:
            vector_store = create_vector_store(pages)
        except Exception as e:
            st.error(f"âŒ Error creating vector store: {e}")
            st.stop()

    if not vector_store:
        st.error("âŒ Vector store creation failed.")
        st.stop()

    with st.spinner("âš™ï¸ Initializing chatbot..."):
        try:
            chain = get_conversational_chain(vector_store)
        except Exception as e:
            st.error(f"âŒ Error initializing chatbot: {e}")
            st.stop()

    if not chain:
        st.error("âŒ Could not load chatbot chain.")
        st.stop()

    st.success("âœ… Chatbot is ready! Ask your questions below.")
    chat_history = []

    query = st.text_input("ğŸ’¬ Ask something from your PDF:", key="user_query")

    if query:
        with st.spinner("âœï¸ Generating answer..."):
            try:
                result = chain({
                    "question": query,
                    "chat_history": chat_history
                })
                answer = result.get("answer", "No answer found.")
                chat_history.append((query, answer))
                st.markdown(f"**ğŸ§  Answer:** {answer}")
            except Exception as e:
                st.error(f"âŒ Error during response generation: {e}")
